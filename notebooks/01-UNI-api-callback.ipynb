{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695d0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41926870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe3c4ce854d457fb48a35a2c9e95457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()  # login with your User Access Token, found at https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee49c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1536, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained=True needed to load UNI2-h weights (and download weights for the first time)\n",
    "timm_kwargs = {\n",
    "            'img_size': 224, \n",
    "            'patch_size': 14, \n",
    "            'depth': 24,\n",
    "            'num_heads': 24,\n",
    "            'init_values': 1e-5, \n",
    "            'embed_dim': 1536,\n",
    "            'mlp_ratio': 2.66667*2,\n",
    "            'num_classes': 0, \n",
    "            'no_embed_class': True,\n",
    "            'mlp_layer': timm.layers.SwiGLUPacked, \n",
    "            'act_layer': torch.nn.SiLU, \n",
    "            'reg_tokens': 8, \n",
    "            'dynamic_img_size': True\n",
    "        }\n",
    "model = timm.create_model(\"hf-hub:MahmoodLab/UNI2-h\", pretrained=True, **timm_kwargs)\n",
    "transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4259cf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1536])\n"
     ]
    }
   ],
   "source": [
    "# create a dummy input tensor of size (1, 3, 224, 224)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# perform a forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5313c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 TIFF files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f9bbd07b0444aaa3313aeeefbb7efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='TIFF File:', layout=Layout(width='500px'), options=('Select a file...', '002_B05.20964B.â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import tifffile\n",
    "import numpy as np\n",
    "\n",
    "# Set your source directory path\n",
    "source_dir = Path(r\"K:\\499-ProjectData\\2025\\P25-0048_Thyroid_Recurrence\\04-Processed_Datasets\\split_cleared_dataset\")\n",
    "\n",
    "def get_tiff_files(directory):\n",
    "    \"\"\"Get all TIFF files excluding those ending with _tissue\"\"\"\n",
    "    if not directory.exists():\n",
    "        print(f\"Directory does not exist: {directory}\")\n",
    "        return []\n",
    "    \n",
    "    tiff_files = []\n",
    "    for file in sorted(directory.glob(\"*.tif*\")):\n",
    "        if not file.stem.endswith(\"_tissue\"):\n",
    "            tiff_files.append(file.name)\n",
    "    return tiff_files\n",
    "\n",
    "def load_volume_and_mask(filename):\n",
    "    \"\"\"Load the selected volume and its corresponding tissue mask\"\"\"\n",
    "    if not filename:\n",
    "        print(\"No file selected\")\n",
    "        return None, None\n",
    "    \n",
    "    volume_path = source_dir / filename\n",
    "    base_name = Path(filename).stem\n",
    "    tissue_filename = f\"{base_name}_tissue.tif\"\n",
    "    tissue_path = source_dir / tissue_filename\n",
    "    \n",
    "    print(f\"Loading volume: {volume_path}\")\n",
    "    volume = tifffile.imread(volume_path)\n",
    "    print(f\"Volume shape: {volume.shape}, dtype: {volume.dtype}\")\n",
    "    \n",
    "    if tissue_path.exists():\n",
    "        print(f\"Loading tissue mask: {tissue_path}\")\n",
    "        tissue_mask = tifffile.imread(tissue_path)\n",
    "        print(f\"Tissue mask shape: {tissue_mask.shape}, dtype: {tissue_mask.dtype}\")\n",
    "    else:\n",
    "        print(f\"Warning: Tissue mask not found at {tissue_path}\")\n",
    "        tissue_mask = None\n",
    "    \n",
    "    return volume, tissue_mask\n",
    "\n",
    "def on_file_selected(change):\n",
    "    \"\"\"Callback when file is selected\"\"\"\n",
    "    selected_file = change['new']\n",
    "    if selected_file:\n",
    "        volume, tissue_mask = load_volume_and_mask(selected_file)\n",
    "        global current_volume, current_tissue_mask\n",
    "        current_volume = volume\n",
    "        current_tissue_mask = tissue_mask\n",
    "\n",
    "# Get available TIFF files\n",
    "tiff_files = get_tiff_files(source_dir)\n",
    "print(f\"Found {len(tiff_files)} TIFF files\")\n",
    "\n",
    "# Create and display dropdown\n",
    "if tiff_files:\n",
    "    file_dropdown = widgets.Dropdown(\n",
    "        options=['Select a file...'] + tiff_files,\n",
    "        value='Select a file...',\n",
    "        description='TIFF File:',\n",
    "        disabled=False,\n",
    "        style={'description_width': '100px'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    file_dropdown.observe(on_file_selected, names='value')\n",
    "    display(file_dropdown)\n",
    "else:\n",
    "    print(f\"No TIFF files found in: {source_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a58bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198075b682b04943be0f6653f6398189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=52, description='Slice:', max=103), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def plot_slice(slice_idx):\n",
    "    \"\"\"Plot a single slice from the volume and tissue mask\"\"\"\n",
    "    if 'current_volume' not in globals() or current_volume is None:\n",
    "        print(\"No volume loaded. Please select a file from the dropdown above.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot volume slice\n",
    "    axes[0].imshow(current_volume[slice_idx], cmap='gray')\n",
    "    axes[0].set_title(f'Volume - Slice {slice_idx}/{current_volume.shape[0]-1}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Plot tissue mask slice if available\n",
    "    if current_tissue_mask is not None:\n",
    "        axes[1].imshow(current_tissue_mask[slice_idx], cmap='gray')\n",
    "        axes[1].set_title(f'Tissue Mask - Slice {slice_idx}/{current_tissue_mask.shape[0]-1}')\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'No tissue mask available', \n",
    "                    ha='center', va='center', transform=axes[1].transAxes)\n",
    "        axes[1].set_title('Tissue Mask - Not Available')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive slider for scrolling through slices\n",
    "if 'current_volume' in globals() and current_volume is not None:\n",
    "    depth = current_volume.shape[0]\n",
    "    interact(plot_slice, \n",
    "             slice_idx=IntSlider(min=0, max=depth-1, step=1, value=depth//2, \n",
    "                                description='Slice:'))\n",
    "else:\n",
    "    print(\"No volume loaded yet. Please select a file from the dropdown above first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
